\def\paperversiondraft{draft}
\def\paperversionnormal{normal}

% If the paper version is set to 'normal' mode keep it,
% otherwise set it to 'draft' mode.
\ifx\paperversion\paperversionnormal
\else
  \def\paperversion{draft}
\fi

\documentclass[a4paper]{scrartcl}

\usepackage{colortbl}

% 'draftonly' environment
\usepackage{environ}
\ifx\paperversion\paperversiondraft
\newenvironment{draftonly}{}{}
\else
\NewEnviron{draftonly}{}
\fi

% Most PL conferences are edited by conference-publishing.com. Follow their
% advice to add the following packages.
%
% The first enables the use of UTF-8 as character encoding, which is the
% standard nowadays. The second ensures the use of font encodings that support
% accented characters etc. (Why should I use this?). The mictotype package
% enables certain features 'to­wards ty­po­graph­i­cal per­fec­tion
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}

\usepackage{xargs}
\usepackage{lipsum}
\usepackage{xparse}
\usepackage{xifthen, xstring}
\usepackage{xspace}
\usepackage{marginnote}
\usepackage{etoolbox}
\usepackage[acronym,shortcuts]{glossaries}
\usepackage{hyperref}

% \usepackage[numbers]{natbib} % for \citeauthor

\input{tex/setup.tex}
% \input{tex/acm.tex}

\usemintedstyle{colorful}

% Newer versions of minted require the 'customlexer' argument for custom lexers
% whereas older versions require the '-x' to be passed via the command line.
\makeatletter
\ifcsdef{minted@optlistcl@quote}
{
\newminted[mlir]{tools/MLIRLexer.py:MLIRLexerOnlyOps}{customlexer, mathescape}
\newminted[xdsl]{tools/MLIRLexer.py:MLIRLexer}{customlexer, mathescape, style=murphy}
\newminted[lean4]{tools/Lean4Lexer.py:Lean4Lexer}{customlexer, mathescape}
}
{
\newminted[mlir]{tools/MLIRLexer.py:MLIRLexerOnlyOps -x}{mathescape}
\newminted[xdsl]{tools/MLIRLexer.py:MLIRLexer -x}{mathescape, style=murphy}
\newminted[lean4]{tools/Lean4Lexer.py:Lean4Lexer -x}{mathescape}
}
\makeatother

% We use the following color scheme
% 
% This scheme is both print-friendly and colorblind safe for
% up to four colors (including the red tones makes it not
% colorblind safe any more)
%
% https://colorbrewer2.org/#type=qualitative&scheme=Paired&n=4

\definecolor{pairedNegOneLightGray}{HTML}{cacaca}
\definecolor{pairedNegTwoDarkGray}{HTML}{827b7b}
\definecolor{pairedOneLightBlue}{HTML}{a6cee3}
\definecolor{pairedTwoDarkBlue}{HTML}{1f78b4}
\definecolor{pairedThreeLightGreen}{HTML}{b2df8a}
\definecolor{pairedFourDarkGreen}{HTML}{33a02c}
\definecolor{pairedFiveLightRed}{HTML}{fb9a99}
\definecolor{pairedSixDarkRed}{HTML}{e31a1c}

\createtodoauthor{grosser}{pairedOneLightBlue}
\createtodoauthor{authorTwo}{pairedTwoDarkBlue}
\createtodoauthor{authorThree}{pairedThreeLightGreen}
\createtodoauthor{authorFour}{pairedFourDarkGreen}
\createtodoauthor{authorFive}{pairedFiveLightRed}
\createtodoauthor{authorSix}{pairedSixDarkRed}

\newacronym{ir}{IR}{Intermediate Representation}

\graphicspath{{./images/}}

% Define macros that are used in this paper
%
% We require all macros to end with a delimiter (by default {}) to enusure
% that LaTeX adds whitespace correctly.
\makeatletter
\newcommand\requiredelimiter[2][########]{%
  \ifdefined#2%
    \def\@temp{\def#2#1}%
    \expandafter\@temp\expandafter{#2}%
  \else
    \@latex@error{\noexpand#2undefined}\@ehc
  \fi
}
\@onlypreamble\requiredelimiter
\makeatother

\newcommand\newdelimitedcommand[2]{
\expandafter\newcommand\csname #1\endcsname{#2}
\expandafter\requiredelimiter
\csname #1 \endcsname
}

\newdelimitedcommand{leanmlir}{LeanMLIR}

\usepackage{booktabs}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\usepackage[verbose]{newunicodechar}
\newunicodechar{₁}{\ensuremath{_1}}
\newunicodechar{₂}{\ensuremath{_2}}
\newunicodechar{∀}{\ensuremath{\forall}}
\newunicodechar{α}{\ensuremath{\alpha}}
\newunicodechar{β}{\ensuremath{\beta}}

% \circled command to print a colored circle.
% \circled{1} pretty-prints "(1)"
% This is useful to refer to labels that are embedded within figures.
\DeclareRobustCommand{\circled}[2][]{%
    \ifthenelse{\isempty{#1}}%
        {\circledbase{pairedOneLightBlue}{#2}}%
        {\autoref{#1}: \hyperref[#1]{\circledbase{pairedOneLightBlue}{#2}}}%
}

% listings don't write "Listing" in autoref without this.
\providecommand*{\listingautorefname}{Listing}
\renewcommand{\sectionautorefname}{Section}
\renewcommand{\subsectionautorefname}{Section}
\renewcommand{\subsubsectionautorefname}{Section}

\newcommand*{\etal}{~\emph{et al.}}

\begin{document}

%% Title information
% \title{First Year Report}       %% [Short Title] is optional;
                                      %% when present, will be used in
                                      %% header instead of Full Title.
\title{Scalable and Modular Verified Compilation via Automated Proofs
for Declarative
Transformations}
\subtitle{First Year Report}

\author{Alex Keizer \small{(ack55)}}
\date{}

% \begin{abstract}
% % An abstract should consist of six main sentences:
% %  1. Introduction. In one sentence, what’s the topic?
% %  2. State the problem you tackle.
% %  3. Summarize (in one sentence) why nobody else has adequately answered the research question yet.
% %  4. Explain, in one sentence, how you tackled the research question.
% %  5. In one sentence, how did you go about doing the research that follows from your big idea.
% %  6. As a single sentence, what’s the key impact of your research?

% % (http://www.easterbrook.ca/steve/2010/01/how-to-write-a-scientific-abstract-in-six-easy-steps/)

% \end{abstract}
\maketitle

A fully end-to-end verified \emph{mainstream} compiler with a small
trusted code base remains somewhat of an unattainable holy grail.
End-to-end verified compilers do exist (e.g., CompCert~\cite{leroyCompCertFormallyVerified} and CakeML~\cite{kumarCakeMLVerifiedImplementation2014}), but the extra
verification burden makes compiler development challenging, relegating
such compilers to specific high-assurance niches. On the other hand,
there are tools which can fully automatically prove the correctness of a
specific compiler transformation (e.g., Alive~\cite{lopesAlive2BoundedTranslation2021}, which has gained
widespread adoption in the LLVM community), but such tools
often rely on SMT solvers to achieve their push-button automation,
making them unsuited in our quest for a minimal trusted code base. I
wish to investigate a middle road: can we verify the core transformation
algorithm separately from specific transformation instances, and then
develop proof automation to show local
correctness of a transformation, without needing input from a formal methods export?

I'll investigate two core components of a verified compiler:
an optimization pass based on peephole optimizations and a code
generator that lowers the compiler IR (Intermediate Representation)
produced by the optimizer into assembly. Of course, a fully end-to-end
compiler would need many more components, such as a verified front-end
that parses source code and transforms it into semantically equivalent
compiler IR, however such components will be out-of-scope for my PhD.

To ensure a minimal trusted code base we'll develop our proofs and proof
automation in Lean. Besides a modern theorem prover, Lean is also aiming
to be a general purpose functional programming language. It is certainly
not the first theorem prover that allows its users to extract executable
code from a formalization, but Lean goes several steps further: the Lean
compiler is itself in large parts written in Lean. Furthermore, proof
automation for Lean is also written in Lean itself. On the one hand,
Lean's rich logic enable us to finely model the semantics of programs.
On the other, Lean itself aims to be a language that is suited for
large-scale software, which necessitates a modern optimizing compiler
backend, but, Lean also has a feature that enables the use of
\emph{compiled} decision procedures in proofs. Using this feature makes
the optimizer part of the trusted codebase for our proofs, and it is
thus crucial for the logical soundness of our system that
mis-compilations do not occur. Combined, this makes Lean a compelling
platform for verified compilation.

For the optimization pass, we choose to operate on a compiler IR with the same semantics as LLVM.
Although others have formalized the semantics of LLVM IR in a proof assistant before
\cite{zhaoFormalVerificationSSABased, zakowskiModularCompositionalExecutable2021}, those efforts
included no proof automation. This will, to my knowledge, be the first
effort to provide fully automated proofs for correctness of LLVM
optimizations in a way that doesn't have to trust an external solver (as
Alive~\cite{lopesAlive2BoundedTranslation2021} and even AliveInLean~\cite{leeAliveInLeanVerifiedLLVM2019} do). Removing
this dependency is important as SMT solvers are large, complex pieces of
software with a history of bugs~\cite{brummayerFuzzingDeltadebuggingSMT2009, mansurDetectingCriticalBugs2020}.

% The next paragraph talks about expanding the peephole rewriter, but that got killed in the planning

% The optimization pass will be instantiated with a set of \emph{peephole
% optimizations}, consisting of program patterns to match for and
% corresponding program patterns to rewrite to. Lean-MLIR
% (\cite{bhatVerifyingPeepholeRewriting2024}), a project in
% development at my research group which I've contributed to, currently
% has a prototype of such an optimizer. However, the current version is
% only able to apply \emph{pure} optimizations. I wish to expand this to
% an optimizer that can apply optimizations involving side effects such as
% memory loads/stores, undefined behaviour, or potentially non-terminating
% control flow, and, crucially, provide push-button proof automation for
% such side-effecting optimizations, using symbolic execution.

After optimization, the next phase will be to generate assembly from our
optimized IR and, crucially, to verify that the generated assembly has
compatible semantics. For maximum trust, we'd like to
use authoritative models of the ISA semantics of whichever platform we
are compiling for to give semantics to the assembly program. Sail~\cite{armstrongISASemanticsARMv8a2019} provides such models: the
Sail model for Arm-A is automatically derived from the official ASL
reference, and the RISC-V model has been adopted by the RISC-V
Foundation. We'll phrase the code generator similarly: by having
fragments of compiler IR to match for, and corresponding fragments of
assembly to rewrite them with. Still, code generation presents some
unique challenges. Firstly, although the transformations themselves
should be simpler, the Sail semantic model will be much larger than our
handwritten LLVM semantics. Secondly, we have to deal with semantics of
different languages (the compiler IR and the assembly language). It is
likely that proof automation for code generation will thus need a
slightly different design than proof automation for peephole
optimizations.

Finally, to model the semantics of LLVM IR in a modular way, we'd like
to follow Zakowski et
al.~(\cite{zakowskiModularCompositionalExecutable2021}) and use
interaction trees (\cite{xiaInteractionTreesRepresenting2020}).
Unfortunately, interaction trees are \emph{coinductive} in nature, to
capture possibly non-terminating programs, and Lean currently lacks
support for coinductive type. Therefore, I'd like to continue the work
that I started in my own master's thesis~\cite{keizerImplementingDefinitionalCodatatype}, which is based on earlier
work by Avigad\etal{}~\cite{avigadDataTypesQuotients2019}, and
continue development of a Lean library for coinductive types.

\subsubsection*{Research Questions}

My research will aim to answer the following questions:
\begin{enumerate}
  \item[\textsc{RQ1}]\label{research-question-1}
    How do we fully automatically verify optimizations involving memory side effects on a mid-level compiler IR, 
    while retaining a minimal trusted code base?

  \item[\textsc{RQ2}]
    How do we fully automatically verify lowerings from a mid-level compiler IR
  to a low-level assembly language, using large-scale, authoritative ISA semantics models?

  \item[\textsc{RQ3}] 
    How do we recover the modularity that interaction trees provide,
      in a theorem prover that does not support coinduction?
\end{enumerate}

\subsubsection*{Criteria For Success}

Question \textsc{RQ1} can be rephrased as: 
how do we reproduce Alive2 in a way that does not trust an SMT solver. 
Luckily, Alive2 has a pretty comprehensive test suite.
I'll evaluate my tool against this same test suite; it should pass all tests,
besides those that use unstructured control flow.

For \textsc{RQ2}, the set of all desired rewrites is known up front: we simply 
need a lowering for each instruction of the mid-level IR.
We'll evaluate our instruction selector by building such a complete set of lowerings.
Ideally, there should be no proof obligation that is specfic to a particular lowering,
this should all be taken care of automatically.

Finally, I ask \textsc{RQ3} because we need interaction trees to define the semantics
of potentially infinite loops. 
We'll consider our interaction tree library successful if
we can provide a similar basic API, and in particular, if we can define the 
semantics we need without referring to details of the underlying QPF construction directly.

\subsubsection*{Verified Compilation and Lean's Extensibility}

Note that the benefits of a verified compilation pipeline go far beyond
simply reducing the chance of bugs. It could lead to a culture
shift in the way software is written. Traditionally, writing compiler
optimizations was a domain reserved for the wise elders who we could
trust to perform the appropriate ``black magic''. Reasoning about the
correctness of a transformation was simply too hard, so we had to rely
on interpersonal trust. Tools like Alive have already caused a shift in
this approach: nowadays PRs that propose adding a new peephole
optimization to LLVM can include a link to Alive's online interface
showing the correctness, meaning no further discussion or review is
required. However, this effect is still limited to making reviews for
proposed additions to LLVM easier.

Lean, again, presents a very interesting opportunity because of it's
\emph{extensibilty}: Lean already has an extensible syntax and a
powerful meta-programming API. In fact, a lot of features that are
considered part of Lean's core are actually implemented using the same
meta-programming facilities that are available to libraries (we'll use
this extensively in~\autoref{a-codatatypes-library-for-lean}). However, we imagine a future where this
extensibility could extend to the backend of the compiler also, such
that a library writer might implement an algorithm in a functional style
that is easy to reason about, but also provide an optimized assembly
\emph{and} a proof that the assembly is equivalent. Traditionally,
hard-coded assembly in a library has been cause for increased scrutiny.
Optimizing is hard, do we really trust the author of this library to
have done it correctly? Verification means we no longer have to trust,
instead we get to have fearless bespoke optimizations!

\section{High-Assurance Translation Validation for Compiler
Optimizations}\label{high-assurance-translation-validation-for-compiler-optimizations}

To answer research question \textsc{RQ1}, I'll build proof automation, in Lean,
which will decide equivalence of program fragments in a compiler IR based on LLVM IR.

LLVM IR is an intermediate representation that sits just above the level
of abstraction of assembly, and has proven a successful platform to
perform optimizations on before finally lowering to platform-specific
assembly. LLVM has been used as a back-end for many mainstream
compilers, such as Clang, Rust and Swift. A crucial property of LLVM IR, is that it is in static single assignment
(SSA) form: rather than operating on a fixed set of registers, LLVM IR
has variables that are assigned exactly once. This form makes it easier
to apply peephole rewrites, as we can simply match for a pattern along
what is called the def-use chain, even if there are unrelated
instructions in between.

Now, although LLVM is a bit higher level than assembly, it's still
low-level and, e.g., features unstructured control flow. The LLVM
community realized that having more structure available would enable
even more optimizations to be done purely locally (i.e., as peephole
rewrites). Thus, MLIR (Multi Level Intermediate Representation) was
born: a framework to define compiler IRs at various levels of
abstraction. MLIR mandates that IRs are in SSA form, and takes care of
syntactic overhead. We can instantiate the framework with a specific set
of operations, called a dialect. Generally, a compiler IR is made up of
a combination of such dialects. For this chapter, we shall focus on an
IR that contains bitvector arithmetic (a fragment of the \texttt{arith}
dialect) memory manipulations (\texttt{ptr} dialect) and structured
control flow (i.e., for and while loops, \texttt{scf} dialect). 
The arithmetic and pointer operations of these dialects have exactly the same semantics as in LLVM, 
but using \emph{structured} control flow puts us just above the level of abstraction of LLVM IR.

\subsection{Lean-MLIR Today}\label{Lean-MLIR-today}

Lean-MLIR is a framework for modelling the \emph{semantics} of MLIR
dialects in Lean, developed by my research group~\cite{bhatVerifyingPeepholeRewriting2024}, focusing on the
\emph{pure} (i.e., side-effect-free) fragment of MLIR dialects.

In particular, Lean-MLIR currently has a model of just the bitvector
arithmetic operations of LLVM IR, and a verified peephole rewriter that
can apply a pure peephole rewrite (i.e., neither the program fragment
being matched on nor the fragment being rewritten to contain
side-effecting operations) and, assuming the local correctness of every
rewrite, we've shown the rewriter preserves the global semantics.

Furthermore, the Lean FRO has, in collaboration with my research group
and me, been developing proof automation for deciding the equality
of fixed-width bitvector expressions~\cite{bovingTamingBitvectorBestiary}. In
particular, this proof automation allows us to fully automatically
decide the local correctness of \emph{pure} optimizations. Note that
although this tactic employs an external (certificate-producing) SAT
solver, it also includes a verified certificate checker, so that the
final proofs do \emph{not} rely on the correctness of the solver. That
said, the checker would be too slow if ran inside the Lean kernel, so to
get decent performance, this tactic \emph{does} rely on the previously
mentioned feature to run the compiled version of a Lean tactic, thus expanding
the trusted code base to include the Lean compiler.
As the paper argues, this is still a much smaller trusted code base than a full
SMT solver.

\subsection{Proof Automation for Side
Effects}\label{proof-automation-for-side-effects}

My contributions to Lean-MLIR are primarily focussed on expanding the framework to 
include support for impure operations with side effects. 
I wish to continue this effort by modelling all operations of the
dialects mentioned before. In particular, the dialect dealing with memory.
The bitvector arithmetic fragment of the previous section is basically the same as \texttt{arith}, and the
framework also already models part of \texttt{scf} (in particular, it
models counting for-loops, but not while-loops with arbitrary conditions
yet), so the main missing piece is a model of memory and memory
operations.

The main innovation in this project will be to build proof automation in
Lean for translation validation on this compiler IR. That is, given a
source and target program (potentially including holes), the tool will
automatically decide the correctness of the transformation. To do this
in the presence of side effects, I'll build a symbolic simulator in Lean, 
which will rely on the previously mentioned bitvector solver to discharge pure
bitvector proof obligations.

\subsection{Refinement and Undefined
Behaviour}\label{refinement-and-undefined-behaviour}

So far, we've talked about semantic equivalence as the condition for
correctness of an optimization, but in reality it's a bit more
complicated because of the notion of undefined behaviour (UB). In short,
if a program has UB, it's legal to change the program to anything.
Conversely, if a source program is fully defined, then it's illegal to
introduce UB in the target. The corresponding relation between programs
is called \emph{refinement}. 

\subsection{Related Work}

We can broadly categorize earlier efforts to apply formal methods to
LLVM into those that formalize the semantics of LLVM, but perform manual
proofs (e.g., VeLLVM~\cite{zhaoFormalVerificationSSABased, zhaoFormalizingLLVMIntermediate2012} 
or work by Zakowski\etal{}~\cite{zakowskiModularCompositionalExecutable2021}) and tools
like Alive~\cite{lopesAlive2BoundedTranslation2021} that perform
fully automated translation validation, but rely on SMT solvers.

AliveInLean is a prototype reimplementation of Alive in Lean that shows how to increase trust without
sacrificing automation~\cite{leeAliveInLeanVerifiedLLVM2019}. AliveInLean helps to justify the reduction from a model of LLVM semantics
to SMT queries. Nonetheless, AliveInLean still trusts the SMT solver and does not support reasoning about memory. 
Our tool should address both of these concerns.

More broadly, CompCert~\cite{leroyCompCertFormallyVerified} and
CakeML~\cite{kumarCakeMLVerifiedImplementation2014} are examples
of fully end-to-end verified compilers. More recent work by Mullen et
al.~\cite{mullenVerifiedPeepholeOptimizations2016} argues for
peephole rewriting as a way to lower proof burden in CompCert
development, but they still prove these rewrites manually.

Katamaran \cite{keuchelVerifiedSymbolicExecution2022} is a
symbolic simulation tool written in Coq. However, this
project focusses on being able to run the simulator outside the ITP
environment, hence eschewing meta-programming. Our main purpose is
modular proof automation, so being tied to Lean is no problem for us,
allowing us to make different implementation choices.

\section{Automatically Verified Instruction Selection using
Authoritative ISA Models}\label{scaling-high-assurance-translation-validation-to-authoritative-isa-models}

After performing optimizations on the level of our compiler IR, we need
to lower this representation to assembly. We'll do this in a very
similar way, by phrasing instruction selection as rewrites that match
for a compiler IR program fragment and rewrite it to an assembly program
fragment. By following a similar approach, we can hopefully reuse some
of the infrastructure we developed in the previous chapter.

By building proof automation in Lean that can automatically verify the correctness of
such lowerings, I'll answer research question \textsc{RQ2}.

\subsection{The RISC-V Dialect}\label{the-risc-v-dialect}

Lopoukhine\etal{}have developed a set of MLIR
dialects that together model RISC-V assembly~\cite{lopoukhineMultiLevelCompilerBackend}. Representing our target
for code generation as an MLIR dialect allows us to use Lean-MLIR,
enabling reuse of the core datastructures provided by the framework, but
the benefits extend much further! Namely, depending on which of the
dialects provided by Lopoukhine\etal{}~we use, our representation of
assembly can (a) be either register allocated, or an assembly-like
SSA IR, and (b) use either structured (for/while loops) or unstructured
control flow (branches).

We'll use these progressively lower level RISC-V IRs as targets for our code
generator, explicitly separating the instruction selection pass, which
we'll implement via a simple rewriter, from a register allocation pass.
Finally, recall that we chose to stick to structured control flow in the
optimization pass to preserve structure. We'll initially do the same in the code
generator, postponing the lowering from structured into unstructured
control flow to the last moment. 

\subsection{Semantics for RISC-V}

So far, we've eliminated any reliance on SMT solvers in pursuit of a
smaller trusted code base. But recall that the semantics model of
whichever language we choose to prove things about is also a crucial
part of the trust story. In the end, if we run our compiler on actual
hardware, then a proof of correctness is only good so long as the actual
hardware behaves the same as our model of the instruction set
architecture (ISA).

One could attempt to formally verify the hardware as well, but that is
well beyond the scope of my PhD. Instead, I'd like to use Sail models as
an authoritative source of truth for ISA semantics~\cite{armstrongISASemanticsARMv8a2019}.
Sail is a domain specific
language for modelling ISA semantics. Various models exist, but in
particular, the Arm-v8 Sail model has been automatically derived from the Arm-internal 
specification~\cite{reidTrustworthySpecificationsARM} and the RISC-V model has
been adopted by RISC-V International~\cite{sammlerIslarisVerificationMachine2022}. 
Using these models as the source of our semantics gives us trust that any discrepancy
between our formalization and actual hardware likely is a bug in the
hardware!

The Sail project currently provides a translation from Sail to Coq,
which has been used previously to formally reason about ISAs. Luckily, a
translation from Sail to Lean is currently being developed, following a
similar strategy to add a backend to sail that emits Lean code---as
opposed to embedding a model of Sail in Lean.

Of course, the Sail semantics will operate on traditional assembly, with
registers allocated and unstructured branches. This should not be a
problem, as lowering a single instruction at any of the progressive
levels of abstraction provided by the RISC-V dialect down to regular 
assembly should not be difficult.

\subsection{Translation Validation}\label{translation-validation}

The core contribution will be proof automation. By treating
instruction selection as a sequence of rewrites, we merely need to
verify that each of these rewrites individually preserves semantics.

This seems like much the same problem that we tackled in the previous
chapters, but there are some subtleties. For one, the rewrites
themselves should be simpler, with many rewrites having only a single
instruction as source and target. However, a Sail-derived semantics
model will be much larger than the handwritten model we'll be using for
the compiler IR, necessitating many more reasoning steps to simplify the
semantics for a single instruction. Many of the details that make the
Sail model so large might be irrelevant in our context, so I'll
investigate ways to simplify the model under specific assumptions. For
example, we could assume we're only compiling user-level programs, which might
allow us to simplify away any complexity to do with kernel-level
instructions in the model.

\subsection{LNSym}\label{lnsym}

During my internship at Amazon, I developed a symbolic simulator for a
simplified fragment of Arm assembly programs, using a handwritten model
of the ARM ISA semantics. My internship focused primarily on making this
symbolic simulator scale to being able to simulate hundreds of
instructions within a reasonable timeframe. I'll be using this symbolic
simulator as a basis for the translation validation tool I aim to
develop in this project, adapting it to the slightly different design constraints in
this context. 

\subsection{Related Work}\label{related-work}

Isla is a symbolic simulator for Sail, which takes in a program in assembly 
together with a Sail model for that assembly language, and outputs a trace of the
execution in Isla Trace Language~\cite{armstrongIslaIntegratingFullScale2021}.
However, Isla relies on an SMT solver to produce this trace.

Islaris is a Coq development, which builds upon Isla and Iris separation logic to 
prove properties about assembly programs using the power and expressivity of a 
theorem prover~\cite{sammlerIslarisVerificationMachine2022}. Their strategy starts by using Isla to transform a program into a trace, and then proving properties about this trace.
To remove the need to trust the SMT solver, Sammler\etal{} also investigated
the use of automated translation validation, which certifies that the trace produced
by Isla agrees with the lowering of the Sail semantics to Coq. This approach 
worked well for RISC-V, but unfortunately did not scale to the much larger Arm model.

Although I'll focus specifically on RISC-V, I'll still choose to reimplement 
the symbolic simulator in Lean, rather than reusing Isla in the same way, 
in the hopes that this approach might prove more scalable.


\section{A Codatatypes Library for
Lean}\label{a-codatatypes-library-for-lean}

In previous chapters, we've glossed over how, exactly, I'll give
semantics to the side-effectful version of our compiler IR. Zakowski et
al.~have written about the benefits of an interaction tree (ITree)
based semantics~\cite{zakowskiModularCompositionalExecutable2021, xiaInteractionTreesRepresenting2020}, so I'd like to use
ITrees also. Sadly, ITrees are coinductive, to properly capture infinite loops, 
and Lean does not support coinductive types.
This is why I'll initially be building a semantics for a fragment of the IR with
trivially terminating for-loops. 
In the current chapter I'll address this shortcoming, by building a Lean library for ITrees and using it to define semantics for potentially infinite loops,
answering research question \textsc{RQ3} in the process.

\subsection{Quotients of Polynomial
Functors}\label{quotients-of-polynomial-functors}

Luckily, we can encode coinductives in Lean's existing logic, using
so-called \emph{quotients of polynomial functors} (QPFs). Avigad\etal{} have written about the low-level construction~\cite{avigadDataTypesQuotients2019}, 
upon which I expanded in my Master's thesis by prototyping a higher-level framework for defining
coinductive types, called QPFTypes. This framework is far from perfect,
and I'll spend some time fixing bugs in the framework. Still, the main
goal will be simply to define interaction trees; not to perfectly polish
the framework.

\subsection{Corecursive Functions}\label{corecursive-functions}

The QPFTypes framework currently only has facilities for defining types;
to define corecursive functions that operate over ITrees we only have
the low-level corecursion principle to work with. However, in their
original development of ITrees, Xia\etal{} in fact provide a set of three
combinators which they claim make working with ITrees more tractable,
and remove the need for users to work directly with Coq's implementation
of corecursive function (which they claim is not compositional). As it
turns out, these combinators are rather similar to the corecursion
principle we do have available. So, for our ITree library
in Lean, we don't have to worry about general corecursive functions; it
suffices to implement the three basic combinators that Xia\etal{} provide.

\subsection{Related Work}\label{related-work-1}

The QPF construction encodes coinductive types as a \emph{library},
instead of having to modify the logical system of Lean to support
coinduction natively --- an approach that is greatly aided by Lean's
excellent meta-programming capabilities. When looking at coinductive
types in other theorem provers, we distinguish between languages like
Isabelle~\cite{traytelCategoryTheoryBased}, which follow the same
coinduction-as-a-library approach, and languages like Coq~\cite{gimenezTutorialRecursiveTypes1998, gimenezApplicationCoinductiveTypes1996}
or Agda which have modified their trusted kernels to support
coinduction.

Isabelle, in particular, is relevant because its construction of
coinductive types, in terms of \emph{bounded natural functors} is
closely related to our construction in terms of QPFs~\cite{furerQuotientsBoundedNatural2022}. There are still new
challenges, however, because Lean's dependent types mean we have to
worry about the distinction between definitional equality (which is a
decidable, but weaker notion of equality) and propositional equality
(which captures more things that are intuitively equal, but requires
proof). Isabelle, in contrast, uses a weaker logical system where all
equalities are decidable.

In contrast, the coinduction-in-the-kernel approach would modify the
kernel to understand coinduction and ensure the kernel recognizes the
desired definitional equalities. However, modifying the trusted kernel
carries a large burden of proof, since the changes could compromise the
logical soundness of the entire system. In fact, the original
implementation of coinduction, called \emph{positive} coinduction, is
nowadays discouraged in favour of an alternative implementation, since
positive coinduction breaks the subject reduction property
\footnote{The subject reduction property states that reducing a program
  does not change its type}\cite{sozeauCorrectCompleteType}. The
coinductives-as-a-library approach requires no new axioms nor changes to
the kernel, and is thus guaranteed not to change any meta properties of
Lean.

\section{Risks and Mitigations}

A mayor risk is that my proposed plan relies on a translation from Sail to Lean 
which is being worked on, but does not yet exist today. Luckily, this translation
is following the footprints of the existing Sail to Coq translation, 
and Lean and Coq are similar enough that there is no reason to expect mayor difficulties.
Furthermore, the SailToLean project currently has a lot of interest.
Still, to allow as much time as possible, I've pushed back work on the chapter that needs this
translation to the end of my PhD. If the translation still does not work as needed by that time,
I can always fall back to a handwritten ISA semantics, as we used in LNSym.

Another risk is that Lean is a relatively less mature theorem prover.
In particular, the style of program verification proofs that will be generated by the proof automation
I propose might be rather different from the type of proofs that most users of Lean
today generate; and thus we might encounter some performance problems inherent to Lean.
In fact, we encountered, and reported, exactly such performance problems while working on LNSym, and this experience means I now know how to debug and mitigate similar
problems.
If my proposed automation does run into limitations of Lean itself,
I'll reduce the scope of what I aim to prove automatically, and 
evaluate and report exactly where the bottlenecks lie.


\section{Time plan}\label{timeplan}

My PhD clock started in Michealmas term 2023, meaning my submission
window is between October 2026 and September 2027, or between 21 and 33
months from now. Picking the lower end of that timeframe gives exactly 7
months per chapter, leaving the final year for writing up the thesis.

Furthermore, I plan to translate each of the technical chapters described in this proposal into a paper, to be submitted at the designated venue. 

As mentioned, I'll work on the instruction selection project last.
I'll list the 3 chapters in order that I'll work on them, which differs from the
chapter order presented so far.

\subsection*{High-Assurance Translation Validation for Compiler Optimizations}
Targeted publication venue: PLDI

\begin{itemize}
\item
  Translation Validation for arithmetic \& bounded, structured control
  flow (2 months)
\item
  Translation Validation for memory side effects (2 months)
\item
  Stress-test and improve scalability of proof automation (2 months)
\item
  Paper writing (1 month)
\end{itemize}

\subsection*{A Codatatypes Library for Lean}\label{a-codatatypes-library-for-lean-1}

Targeted publication venue: ITP

\begin{itemize}
\item
  Bugfix framework to accept ITree type definition (2 months)
\item
  Define basic ITree API, including combinators (2 months)
\item
  Evaluate ITrees by expanding compiler IR semantics to infinite loops
  (2 months)
\item
  Paper writing (1 month)
\end{itemize}

\subsection*{Automatically Verified Instruction Selection using
Authoritative ISA Models}\label{scaling-high-assurance-translation-validation-to-authoritative-isa-models-1}

Targeted publication venue: PLDI

\begin{itemize}
\item
  Define lowering from compiler IR to assembly (2 months)
\item
  Translation validation for unstructured control flow (2 months)
\item
  Evaluate and improve scalability of SailToLean-generated ISA model (2
  months)
\item
  Paper writing (1 month)
\end{itemize}







%% Bibliography
\bibliographystyle{plain}
\bibliography{references}


\end{document}
