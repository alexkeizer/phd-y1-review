@inproceedings{avigadDataTypesQuotients2019,
  title = {Data {{Types}} as {{Quotients}} of {{Polynomial Functors}}},
  booktitle = {10th {{International Conference}} on {{Interactive Theorem Proving}} ({{ITP}} 2019)},
  author = {Avigad, Jeremy and Carneiro, Mario and Hudon, Simon},
  editor = {Harrison, John and O'Leary, John and Tolmach, Andrew},
  date = {2019},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {141},
  pages = {6:1--6:19},
  publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
  location = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.ITP.2019.6},
  url = {https://doi.org/10.4230/LIPIcs.ITP.2019.6},
  urldate = {2022-11-23},
  isbn = {978-3-95977-122-1},
  keywords = {_tablet,000 Computer science knowledge general works,coinductive types,Computer Science,data types,inductive types,polynomial functors},
  file = {/home/alex/Zotero/storage/FL3P6RZR/Avigad et al. - 2019 - Data Types as Quotients of Polynomial Functors.pdf;/home/alex/Zotero/storage/Q2N47BF6/11061.html}
}

@thesis{basoldMixedInductiveCoinductiveReasoning2018,
  type = {phdthesis},
  title = {Mixed {{Inductive-Coinductive Reasoning Types}}, {{Programs}} and {{Logic}}},
  author = {Basold, H.},
  date = {2018},
  institution = {Radboud Universiteit},
  location = {Nijmegen},
  url = {https://repository.ubn.ru.nl/handle/2066/190323},
  urldate = {2023-01-16},
  abstract = {Induction and coinduction are two complementary techniques used in mathematics and computer science. These techniques occur together, for example, in control systems: On the one hand, control systems are expected to run until turned off and to always react to their environment. This is what we call coinductive computations. On the other hand, they have to make internal computations. Restricting these computations to terminating, that is inductive, computations ensures that the systems continue to react to their environment. We develop in this thesis techniques for programming inductive-coinductive systems, and for describing their properties and proving these properties. The focus is on developing formal languages, in which proofsare written by humans and can be verified by a computer. This ensures the correctness of those proofs and thereby of the programmed systems. Due to their generality, the developed languages are also applicable to the formalisation of mathematics.},
  langid = {english},
  pagetotal = {278},
  annotation = {Accepted: 2018-04-13T20:35:11Z},
  file = {/home/alex/Zotero/storage/LF7T8NIY/Basold_2018_Mixed Inductive-Coinductive Reasoning Types, Programs and Logic.pdf}
}

@inproceedings{bizjakGuardedDependentType2016,
  title = {Guarded {{Dependent Type Theory}} with {{Coinductive Types}}},
  booktitle = {Foundations of {{Software Science}} and {{Computation Structures}}},
  author = {Bizjak, Aleš and Grathwohl, Hans Bugge and Clouston, Ranald and Møgelberg, Rasmus E. and Birkedal, Lars},
  editor = {Jacobs, Bart and Löding, Christof},
  date = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {20--35},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-49630-5_2},
  abstract = {We present guarded dependent type theory, \$\$\textbackslash mathsf \{gDTT\}\$\$gDTT, an extensional dependent type theory with a ‘later’ modality and clock quantifiers for programming and proving with guarded recursive and coinductive types. The later modality is used to ensure the productivity of recursive definitions in a modular, type based, way. Clock quantifiers are used for controlled elimination of the later modality and for encoding coinductive types using guarded recursive types. Key to the development of \$\$\textbackslash mathsf \{gDTT\}\$\$gDTTare novel type and term formers involving what we call ‘delayed substitutions’. These generalise the applicative functor rules for the later modality considered in earlier work, and are crucial for programming and proving with dependent types. We show soundness of the type theory with respect to a denotational model.},
  isbn = {978-3-662-49630-5},
  langid = {english},
  keywords = {Applicative Functor,Clock Variable,Elimination Rule,Guarded Recursion,Modal Types,Type Isomorphism,Type Theory},
  file = {/home/alex/Zotero/storage/JI3W8VBG/Bizjak et al_2016_Guarded Dependent Type Theory with Coinductive Types.pdf;/home/alex/Zotero/storage/WK24KIF3/Bizjak et al. - 2016 - Guarded Dependent Type Theory with Coinductive Typ.pdf}
}

@incollection{blanchetteFriendsBenefitsImplementing2017,
  title = {Friends with {{Benefits}}: {{Implementing Corecursion}} in {{Foundational Proof Assistants}}},
  shorttitle = {Friends with {{Benefits}}},
  booktitle = {Programming {{Languages}} and {{Systems}}},
  author = {Blanchette, Jasmin Christian and Bouzy, Aymeric and Lochbihler, Andreas and Popescu, Andrei and Traytel, Dmitriy},
  editor = {Yang, Hongseok},
  date = {2017},
  volume = {10201},
  pages = {111--140},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-54434-1_5},
  url = {https://doi.org/10.1007/978-3-662-54434-1_5},
  urldate = {2023-01-15},
  abstract = {We introduce AmiCo, a tool that extends a proof assistant, Isabelle/HOL, with flexible function definitions well beyond primitive corecursion. All definitions are certified by the assistant’s inference kernel to guard against inconsistencies. A central notion is that of friends: functions that preserve the productivity of their arguments and that are allowed in corecursive call contexts. As new friends are registered, corecursion benefits by becoming more expressive. We describe this process and its implementation, from the user’s specification to the synthesis of a higher-order definition to the registration of a friend. We show some substantial case studies where our approach makes a difference.},
  isbn = {978-3-662-54433-4 978-3-662-54434-1},
  langid = {english},
  file = {/home/alex/Zotero/storage/IDP89HIY/Blanchette et al. - 2017 - Friends with Benefits Implementing Corecursion in.pdf;/home/alex/Zotero/storage/YSDWMZG4/Blanchette et al_2017_Friends with Benefits.pdf}
}

@article{blanchetteSoundnessCompletenessProofs2017,
  title = {Soundness and {{Completeness Proofs}} by {{Coinductive Methods}}},
  author = {Blanchette, Jasmin Christian and Popescu, Andrei and Traytel, Dmitriy},
  date = {2017-01-01},
  journaltitle = {Journal of Automated Reasoning},
  shortjournal = {J Autom Reasoning},
  volume = {58},
  number = {1},
  pages = {149--179},
  issn = {1573-0670},
  doi = {10.1007/s10817-016-9391-3},
  url = {https://doi.org/10.1007/s10817-016-9391-3},
  urldate = {2024-06-05},
  abstract = {We show how codatatypes can be employed to produce compact, high-level proofs of key results in logic: the soundness and completeness of proof systems for variations of first-order logic. For the classical completeness result, we first establish an abstract property of possibly infinite derivation trees. The abstract proof can be instantiated for a wide range of Gentzen and tableau systems for various flavors of first-order logic. Soundness becomes interesting as soon as one allows infinite proofs of first-order formulas. This forms the subject of several cyclic proof systems for first-order logic augmented with inductive predicate definitions studied in the literature. All the discussed results are formalized using Isabelle/HOL’s recently introduced support for codatatypes and corecursion. The development illustrates some unique features of Isabelle/HOL’s new coinductive specification language such as nesting through non-free types and mixed recursion–corecursion.},
  langid = {english},
  keywords = {Codatatypes,Completeness,First-order logic,Gentian systems,Isabelle/HOL,Lazy evaluation,Proof assistants,Soundness},
  file = {/home/alex/Zotero/storage/J74TXVES/Blanchette et al_2017_Soundness and Completeness Proofs by Coinductive Methods.pdf}
}

@inproceedings{brummayerFuzzingDeltadebuggingSMT2009,
  title = {Fuzzing and Delta-Debugging {{SMT}} Solvers},
  booktitle = {Proceedings of the 7th {{International Workshop}} on {{Satisfiability Modulo Theories}}},
  author = {Brummayer, Robert and Biere, Armin},
  date = {2009-08-02},
  series = {{{SMT}} '09},
  pages = {1--5},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1670412.1670413},
  url = {https://doi.org/10.1145/1670412.1670413},
  urldate = {2024-06-05},
  abstract = {SMT solvers are widely used as core engines in many applications. Therefore, robustness and correctness are essential criteria. Current testing techniques used by developers of SMT solvers do not satisfy the high demand for correct and robust solvers, as our testing experiments show. To improve this situation, we propose to complement traditional testing techniques with grammar-based blackbox fuzz testing, combined with delta-debugging. We demonstrate the effectiveness of our approach and report on critical bugs and incorrect results which we found in current state-of-the-art SMT solvers for bit-vectors and arrays.},
  isbn = {978-1-60558-484-3},
  file = {/home/alex/Zotero/storage/WE39XV8J/Brummayer_Biere_2009_Fuzzing and delta-debugging SMT solvers.pdf}
}

@article{chevalFormalDefinitionsProofs,
  title = {Formal {{Definitions}} and {{Proofs}} for {{Partial}} ({{Co}}){{Recursive Functions}}},
  author = {Cheval, Horatiu and Nowak, David and Rusu, Vlad},
  abstract = {Partial functions are a key concept in programming. Without partiality a programming language has limited expressiveness - it is not Turing-complete, hence, some programs cannot be written. In functional programming languages, partiality mostly originates from the non-termination of recursive functions. Corecursive functions are another source of partiality: here, the issue is not non-termination, but the inability to produce arbitrary large, finite approximations of a theoretically infinite output.},
  langid = {english},
  file = {/home/alex/Zotero/storage/AZKSL3EL/Cheval et al. - Formal Definitions and Proofs for Partial (Co)Recu.pdf}
}

@inproceedings{demouraLeanTheoremProver2015,
  title = {The {{Lean Theorem Prover}} ({{System Description}})},
  booktitle = {Automated {{Deduction}} - {{CADE-25}}},
  author = {family=Moura, given=Leonardo, prefix=de, useprefix=true and Kong, Soonho and Avigad, Jeremy and family=Doorn, given=Floris, prefix=van, useprefix=true and family=Raumer, given=Jakob, prefix=von, useprefix=true},
  editor = {Felty, Amy P. and Middeldorp, Aart},
  date = {2015},
  volume = {9195},
  pages = {378--388},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-21401-6_26},
  url = {https://doi.org/10.1007/978-3-319-21401-6_26},
  urldate = {2023-01-10},
  abstract = {Lean is a new open source theorem prover being developed at Microsoft Research and Carnegie Mellon University, with a small trusted kernel based on dependent type theory. It aims to bridge the gap between interactive and automated theorem proving, by situating automated tools and methods in a framework that supports user interaction and the construction of fully specified axiomatic proofs. Lean is an ongoing and long-term effort, but it already provides many useful components, integrated development environments, and a rich API which can be used to embed it into other systems. It is currently being used to formalize category theory, homotopy type theory, and abstract algebra. We describe the project goals, system architecture, and main features, and we discuss applications and continuing work.},
  isbn = {978-3-319-21400-9 978-3-319-21401-6},
  file = {/home/alex/Zotero/storage/GLLTAUIJ/de Moura et al_2015_The Lean Theorem Prover (System Description).pdf}
}

@article{eldridgeMLIRHardwareCompiler,
  title = {{{MLIR}} as {{Hardware Compiler Infrastructure}}},
  author = {Eldridge, Schuyler and Barua, Prithayan and Chapyzhenka, Aliaksei and Izraelevitz, Adam and Koenig, Jack and Lattner, Chris and Lenharth, Andrew and Leontiev, George and Schuiki, Fabian and Sunder, Ram and Young, Andrew and Xia, Richard},
  langid = {english},
  file = {/home/alex/Zotero/storage/2926Z9MR/Eldridge et al. - MLIR as Hardware Compiler Infrastructure.pdf}
}

@article{furerQuotientsBoundedNatural2022,
  title = {Quotients of {{Bounded Natural Functors}}},
  author = {Fürer, Basil and Lochbihler, Andreas and Schneider, Joshua and Traytel, Dmitriy},
  date = {2022-02-01},
  journaltitle = {Logical Methods in Computer Science},
  volume = {18},
  number = {1},
  eprint = {2104.05348},
  eprinttype = {arxiv},
  eprintclass = {cs},
  issn = {1860-5974},
  doi = {10.46298/lmcs-18(1:23)2022},
  url = {https://lmcs.episciences.org/9022},
  urldate = {2022-10-30},
  abstract = {The functorial structure of type constructors is the foundation for many definition and proof principles in higher-order logic (HOL). For example, inductive and coinductive datatypes can be built modularly from bounded natural functors (BNFs), a class of well-behaved type constructors. Composition, fixpoints, and—under certain conditions—subtypes are known to preserve the BNF structure. In this article, we tackle the preservation question for quotients, the last important principle for introducing new types in HOL. We identify sufficient conditions under which a quotient inherits the BNF structure from its underlying type. Surprisingly, lifting the structure in the obvious manner fails for some quotients, a problem that also affects the quotients of polynomial functors used in the Lean proof assistant. We provide a strictly more general lifting scheme that supports such problematic quotients. We extend the Isabelle/HOL proof assistant with a command that automates the registration of a quotient type as a BNF, reducing the proof burden on the user from the full set of BNF axioms to our inheritance conditions. We demonstrate the command’s usefulness through several case studies.},
  langid = {english},
  keywords = {Computer Science - Logic in Computer Science,Computer Science - Programming Languages},
  file = {/home/alex/Zotero/storage/NHZZBL8R/Fürer et al_2022_Quotients of Bounded Natural Functors.pdf}
}

@inproceedings{gimenezApplicationCoinductiveTypes1996,
  title = {An Application of Co-Inductive Types in {{Coq}}: {{Verification}} of the Alternating Bit Protocol},
  shorttitle = {An Application of Co-Inductive Types in {{Coq}}},
  booktitle = {Types for {{Proofs}} and {{Programs}}},
  author = {Giménez, Eduardo},
  editor = {Berardi, Stefano and Coppo, Mario},
  editora = {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan},
  editoratype = {redactor},
  date = {1996},
  volume = {1158},
  pages = {135--152},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-61780-9_67},
  url = {https://doi.org/10.1007/3-540-61780-9_67},
  urldate = {2023-01-10},
  abstract = {We describe an experience concerning the implementation and use of co-inductive types in the proof editor Coq. Co-inductive types are recursive types which, opposite to inductive ones, may be inhabited by infinite objects. In order to illustrate their use in Coq, we describe an axiomatisation of a calculus of broadcasting systems where non-ending processes are represented using infinite objects. This calculus is then used for developing a verification proof of the alternating bit protocol.},
  isbn = {978-3-540-61780-8 978-3-540-70722-6}
}

@report{gimenezTutorialRecursiveTypes1998,
  title = {A {{Tutorial}} on {{Recursive Types}} in {{Coq}}},
  author = {Giménez, Eduardo},
  date = {1998-05-01},
  institution = {INRIA},
  url = {https://hal.inria.fr/inria-00069950/document},
  urldate = {2023-01-10},
  abstract = {This document is an introduction to the definition and use of recursive types in the Coq proof environment. It explains how recursive types like natural numbers and infinite streams are defined in Coq, and the kind of proof techniques that can be used to reason about them (case analysis, induction, inversion of predicates, co-induction, etc). Each technique is illustrated through an executable and self-contained Coq script.},
  file = {/home/alex/Zotero/storage/MBC5B6UI/Giménez_1998_A Tutorial on Recursive Types in Coq.pdf}
}

@article{hurPowerParameterizationCoinductive,
  title = {The {{Power}} of {{Parameterization}} in {{Coinductive Proof}}},
  author = {Hur, Chung-Kil and Neis, Georg and Dreyer, Derek and Vafeiadis, Viktor},
  abstract = {Coinduction is one of the most basic concepts in computer science. It is therefore surprising that the commonly-known lattice-theoretic accounts of the principles underlying coinductive proofs are lacking in two key respects: they do not support compositional reasoning (i.e., breaking proofs into separate pieces that can be developed in isolation), and they do not support incremental reasoning (i.e., developing proofs interactively by starting from the goal and generalizing the coinduction hypothesis repeatedly as necessary).},
  langid = {english},
  file = {/home/alex/Zotero/storage/RVJ785CB/Hur et al. - The Power of Parameterization in Coinductive Proof.pdf}
}

@inproceedings{jungHigherorderGhostState2016,
  title = {Higher-Order Ghost State},
  booktitle = {Proceedings of the 21st {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  author = {Jung, Ralf and Krebbers, Robbert and Birkedal, Lars and Dreyer, Derek},
  date = {2016-09-04},
  pages = {256--269},
  publisher = {ACM},
  location = {Nara Japan},
  doi = {10.1145/2951913.2951943},
  url = {https://dl.acm.org/doi/10.1145/2951913.2951943},
  urldate = {2024-06-11},
  abstract = {The development of concurrent separation logic (CSL) has sparked a long line of work on modular verification of sophisticated concurrent programs. Two of the most important features supported by several existing extensions to CSL are higher-order quantification and custom ghost state. However, none of the logics that support both of these features reap the full potential of their combination. In particular, none of them provide general support for a feature we dub “higher-order ghost state”: the ability to store arbitrary higherorder separation-logic predicates in ghost variables. In this paper, we propose higher-order ghost state as a interesting and useful extension to CSL, which we formalize in the framework of Jung et al.’s recently developed Iris logic. To justify its soundness, we develop a novel algebraic structure called CMRAs (“cameras”), which can be thought of as “step-indexed partial commutative monoids”. Finally, we show that Iris proofs utilizing higher-order ghost state can be effectively formalized in Coq, and discuss the challenges we faced in formalizing them.},
  eventtitle = {{{ICFP}}'16: {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  isbn = {978-1-4503-4219-3},
  langid = {english},
  file = {/home/alex/Zotero/storage/ENV2VECP/Jung et al. - 2016 - Higher-order ghost state.pdf}
}

@inproceedings{jungIrisMonoidsInvariants2015,
  title = {Iris: {{Monoids}} and {{Invariants}} as an {{Orthogonal Basis}} for {{Concurrent Reasoning}}},
  shorttitle = {Iris},
  booktitle = {Proceedings of the 42nd {{Annual ACM SIGPLAN-SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
  author = {Jung, Ralf and Swasey, David and Sieczkowski, Filip and Svendsen, Kasper and Turon, Aaron and Birkedal, Lars and Dreyer, Derek},
  date = {2015-01-14},
  pages = {637--650},
  publisher = {ACM},
  location = {Mumbai India},
  doi = {10.1145/2676726.2676980},
  url = {https://dl.acm.org/doi/10.1145/2676726.2676980},
  urldate = {2024-06-11},
  abstract = {We present Iris, a concurrent separation logic with a simple premise: monoids and invariants are all you need. Partial commutative monoids enable us to express—and invariants enable us to enforce—user-defined protocols on shared state, which are at the conceptual core of most recent program logics for concurrency. Furthermore, through a novel extension of the concept of a view shift, Iris supports the encoding of logically atomic specifications, i.e., Hoare-style specs that permit the client of an operation to treat the operation essentially as if it were atomic, even if it is not.},
  eventtitle = {{{POPL}} '15: {{The}} 42nd {{Annual ACM SIGPLAN-SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
  isbn = {978-1-4503-3300-9},
  langid = {english},
  file = {/home/alex/Zotero/storage/QMK68DNE/Jung et al. - 2015 - Iris Monoids and Invariants as an Orthogonal Basi.pdf}
}

@article{kastnerCompCertPracticalExperience,
  title = {{{CompCert}}: {{Practical Experience}} on {{Integrating}} and {{Qualifying}} a {{Formally Verified Optimizing Compiler}}},
  author = {Kästner, Daniel and Barrho, Jörg and Wünsche, Ulrich and Schlickling, Marc and Schommer, Bernhard and Schmidt, Michael and Ferdinand, Christian and Leroy, Xavier and Blazy, Sandrine},
  abstract = {CompCert is the first commercially available optimizing compiler that is formally verified, using machineassisted mathematical proofs, to be exempt from miscompilation. The executable code it produces is proved to behave exactly as specified by the semantics of the source C program. This article gives an overview of the use of CompCert to gain certification credits for a highly safety-critical industry application, certified according to IEC 60880 [7]. We will briefly introduce the target application, illustrate the process of changing the existing compiler infrastructure to CompCert, and discuss performance characteristics. The main part focuses on the tool qualification strategy, in particular on how to take advantage of the formal correctness proof in the certification process.},
  langid = {english},
  file = {/home/alex/Zotero/storage/R7MQXT3S/Kästner et al. - CompCert Practical Experience on Integrating and .pdf}
}

@thesis{keizerImplementingDefinitionalCo,
  title = {Implementing a Definitional (Co)Datatype Package in {{Lean}} 4, Based on Quotients of Polynomial Functors},
  author = {Keizer, Alex Christian},
  institution = {University of Amsterdam},
  location = {Amsterdam}
}

@article{keizerMScThesisAfstudeerscriptie,
  title = {{{MSc Thesis}} ({{Afstudeerscriptie}})},
  author = {Keizer, Alex C},
  langid = {english},
  file = {/home/alex/Zotero/storage/24JR94EN/Keizer - MSc Thesis (Afstudeerscriptie).pdf}
}

@online{lattnerMLIRCompilerInfrastructure2020,
  title = {{{MLIR}}: {{A Compiler Infrastructure}} for the {{End}} of {{Moore}}'s {{Law}}},
  shorttitle = {{{MLIR}}},
  author = {Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  date = {2020-02-29},
  eprint = {2002.11054},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2002.11054},
  url = {https://doi.org/10.48550/arXiv.2002.11054},
  urldate = {2023-03-22},
  abstract = {This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR aims to address software fragmentation, improve compilation for heterogeneous hardware, significantly reduce the cost of building domain specific compilers, and aid in connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and also across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, and identifying the challenges and opportunities posed by this novel design point in design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and educational opportunities for future programming languages, compilers, execution environments, and computer architecture. The paper also presents the rationale for MLIR, its original design principles, structures and semantics.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Programming Languages,MLIR},
  file = {/home/alex/Zotero/storage/VH4NVMLW/Lattner et al_2020_MLIR.pdf;/home/alex/Zotero/storage/TL7J6TIX/2002.html}
}

@article{leroyCompCertFormallyVerified,
  title = {{{CompCert}} - {{A Formally Verified Optimizing Compiler}}},
  author = {Leroy, Xavier and Blazy, Sandrine and Kästner, Daniel and Schommer, Bernhard and Pister, Markus and Ferdinand, Christian},
  abstract = {CompCert is the first commercially available optimizing compiler that is formally verified, using machineassisted mathematical proofs, to be exempt from miscompilation. The executable code it produces is proved to behave exactly as specified by the semantics of the source C program. This article gives an overview of the design of CompCert and its proof concept and then focuses on aspects relevant for industrial application. We briefly summarize practical experience and give an overview of recent CompCert development aiming at industrial usage. CompCert’s intended use is the compilation of life-critical and mission-critical software meeting high levels of assurance. In this context tool qualification is of paramount importance. We summarize the confidence argument of CompCert and give an overview of relevant qualification strategies.},
  langid = {english},
  file = {/home/alex/Zotero/storage/RM3MG3JB/Leroy et al. - CompCert - A Formally Verified Optimizing Compiler.pdf}
}

@inproceedings{lopesAlive2BoundedTranslation2021,
  title = {Alive2: Bounded Translation Validation for {{LLVM}}},
  shorttitle = {Alive2},
  booktitle = {Proceedings of the 42nd {{ACM SIGPLAN International Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Lopes, Nuno P. and Lee, Juneyoung and Hur, Chung-Kil and Liu, Zhengyang and Regehr, John},
  date = {2021-06-18},
  series = {{{PLDI}} 2021},
  pages = {65--79},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3453483.3454030},
  url = {https://doi.org/10.1145/3453483.3454030},
  urldate = {2024-06-05},
  abstract = {We designed, implemented, and deployed Alive2: a bounded translation validation tool for the LLVM compiler’s intermediate representation (IR). It limits resource consumption by, for example, unrolling loops up to some bound, which means there are circumstances in which it misses bugs. Alive2 is designed to avoid false alarms, is fully automatic through the use of an SMT solver, and requires no changes to LLVM. By running Alive2 over LLVM’s unit test suite, we discovered and reported 47 new bugs, 28 of which have been fixed already. Moreover, our work has led to eight patches to the LLVM Language Reference—the definitive description of the semantics of its IR—and we have participated in numerous discussions with the goal of clarifying ambiguities and fixing errors in these semantics. Alive2 is open source and we also made it available on the web, where it has active users from the LLVM community.},
  isbn = {978-1-4503-8391-2},
  keywords = {Automatic Software Verification,Compilers,IR Semantics,Translation Validation},
  file = {/home/alex/Zotero/storage/A5P997CM/Lopes et al_2021_Alive2.pdf}
}

@unpublished{paulinoMetaprogrammingLean,
  title = {Metaprogramming in {{Lean}} 4},
  author = {Paulino, Arthur and Testa, Damiano and Ayers, Edward and Böving, Henrik and Limperg, Jannis and Gadgil, Siddhartha and Bhat, Siddharth},
  url = {https://github.com/arthurpaulino/lean4-metaprogramming-book},
  langid = {english},
  note = {Online Book. \url{https://github.com/arthurpaulino/lean4-metaprogramming-book}},
  file = {/home/alex/Zotero/storage/STURDSJ9/Paulino et al_Metaprogramming in Lean 4.pdf}
}

@inproceedings{ruttenAutomataCoinductionExercise1998,
  title = {Automata and Coinduction (an Exercise in Coalgebra)},
  booktitle = {{{CONCUR}}'98 {{Concurrency Theory}}},
  author = {Rutten, J. J. M. M.},
  editor = {Sangiorgi, Davide and family=Simone, given=Robert, prefix=de, useprefix=true},
  date = {1998},
  pages = {194--218},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/BFb0055624},
  abstract = {The classical theory of deterministic automata is presented in terms of the notions of homomorphism and bisimulation, which are the cornerstones of the theory of (universal) coalgebra. This leads to a transparent and uniform presentation of automata theory and yields some new insights, amongst which coinduction proof methods for language equality and language inclusion. At the same time, the present treatment of automata theory may serve as an introduction to coalgebra.},
  isbn = {978-3-540-68455-8},
  langid = {english},
  file = {/home/alex/Zotero/storage/BPG295JC/Rutten_1998_Automata and coinduction (an exercise in coalgebra).pdf}
}

@book{sangiorgiIntroductionBisimulationCoinduction2011,
  title = {Introduction to {{Bisimulation}} and {{Coinduction}}},
  author = {Sangiorgi, Davide},
  date = {2011-10-13},
  publisher = {Cambridge University Press},
  abstract = {Induction is a pervasive tool in computer science and mathematics for defining objects and reasoning on them. Coinduction is the dual of induction and as such it brings in quite different tools. Today, it is widely used in computer science, but also in other fields, including artificial intelligence, cognitive science, mathematics, modal logics, philosophy and physics. The best known instance of coinduction is bisimulation, mainly employed to define and prove equalities among potentially infinite objects: processes, streams, non-well-founded sets, etc. This book presents bisimulation and coinduction: the fundamental concepts and techniques and the duality with induction. Each chapter contains exercises and selected solutions, enabling students to connect theory with practice. A special emphasis is placed on bisimulation as a behavioural equivalence for processes. Thus the book serves as an introduction to models for expressing processes (such as process calculi) and to the associated techniques of operational and algebraic analysis.},
  isbn = {978-1-139-50283-2},
  langid = {english},
  pagetotal = {261},
  keywords = {Computers / General,Computers / Languages / General,Computers / Networking / General,Mathematics / Logic}
}

@article{sozeauCorrectCompleteType,
  title = {Correct and {{Complete Type Checking}} and {{Certified Erasure}} for {{Coq}}, in {{Coq}}},
  author = {Sozeau, Matthieu and Forster, Yannick and Lennon-Bertrand, Meven and Nielsen, Jakob Botsch and Tabareau, Nicolas and Winterhalter, Théo},
  abstract = {Coq is built around a well-delimited kernel that performs type checking for definitions in a variant of the Calculus of Inductive Constructions (CIC). Although the metatheory of CIC is very stable and reliable, the correctness of its implementation in Coq is less clear. Indeed, implementing an efficient type checker for CIC is a rather complex task, and many parts of the code rely on implicit invariants which can easily be broken by further evolution of the code. Therefore, on average, one critical bug has been found every year in Coq. This paper presents the first implementation of a type checker for the kernel of Coq (without the module system, template polymorphism and 𝜂-conversion), which is proven sound and complete in Coq with respect to its formal specification. Note that because of Gödel’s second incompleteness theorem, there is no hope to prove completely the soundness of the specification of Coq inside Coq (in particular strong normalization), but it is possible to prove the correctness and completeness of the implementation assuming soundness of the specification, thus moving from a trusted code base (TCB) to a trusted theory base (TTB) paradigm. Our work is based on the MetaCoq project which provides meta-programming facilities to work with terms and declarations at the level of the kernel. We verify a relatively efficient type checker based on the specification of the typing relation of the Polymorphic, Cumulative Calculus of Inductive Constructions (PCUIC) at the basis of Coq. It is worth mentioning that during the verification process, we have found a source of incompleteness in Coq’s official type checker, which has then been fixed in Coq 8.14 thanks to our work. In addition to the kernel implementation, another essential feature of Coq is the so-called extraction mechanism: the production of executable code in functional languages from Coq definitions. We present a verified version of this subtle type and proof erasure step, therefore enabling the verified extraction of a safe type checker for Coq in the future. CCS Concepts: • Theory of computation → Type theory.},
  langid = {english},
  file = {/home/alex/Zotero/storage/W6DX4XDL/Sozeau et al. - Correct and Complete Type Checking and Certified E.pdf}
}

@inproceedings{themathlibcommunityLeanMathematicalLibrary2020,
  title = {The Lean Mathematical Library},
  booktitle = {Proceedings of the 9th {{ACM SIGPLAN International Conference}} on {{Certified Programs}} and {{Proofs}}},
  author = {{The mathlib Community}},
  date = {2020-01-20},
  pages = {367--381},
  publisher = {ACM},
  location = {New Orleans LA USA},
  doi = {10.1145/3372885.3373824},
  url = {https://dl.acm.org/doi/10.1145/3372885.3373824},
  urldate = {2023-01-10},
  eventtitle = {{{POPL}} '20: 47th {{Annual ACM SIGPLAN Symposium}} on {{Principles}} of {{Programming Languages}}},
  isbn = {978-1-4503-7097-4},
  langid = {english},
  keywords = {formal proof,Lean},
  file = {/home/alex/Zotero/storage/X5R7F6YP/The mathlib Community_2020_The lean mathematical library.pdf}
}

@thesis{traytelCategoryTheoryBased,
  type = {mathesis},
  title = {A Category Theory Based (Co)Datatype Package for {{Isabelle}}/{{HOL}}},
  author = {Traytel, Dmytro},
  institution = {TU München},
  location = {München},
  url = {https://www21.in.tum.de/~traytel/mscthesis.pdf},
  langid = {english},
  file = {/home/alex/Zotero/storage/AQIK6MRC/Traytel - A category theory based (co)datatype package for I}
}

@article{ullrichNotationsHygienicMacro2022,
  title = {Beyond {{Notations}}: {{Hygienic Macro Expansion}} for {{Theorem Proving Languages}}},
  shorttitle = {Beyond {{Notations}}},
  author = {Ullrich, Sebastian and family=Moura, given=Leonardo, prefix=de, useprefix=true},
  date = {2022-04-12},
  journaltitle = {Logical Methods in Computer Science},
  volume = {18},
  number = {2},
  publisher = {Episciences.org},
  doi = {10.46298/lmcs-18(2:1)2022},
  url = {https://doi.org/10.46298/lmcs-18(2:1)2022},
  urldate = {2022-10-30},
  abstract = {In interactive theorem provers (ITPs), extensible syntax is not only crucial to lower the cognitive burden of manipulating complex mathematical objects, but plays a critical role in developing reusable abstractions in libraries. Most ITPs support such extensions in the form of restrictive “syntax sugar” substitutions and other ad hoc mechanisms, which are too rudimentary to support many desirable abstractions. As a result, libraries are littered with unnecessary redundancy. Tactic languages in these systems are plagued by a seemingly unrelated issue: accidental name capture, which often produces unexpected and counterintuitive behavior. We take ideas from the Scheme family of programming languages and solve these two problems simultaneously by proposing a novel hygienic macro system custom-built for ITPs. We further describe how our approach can be extended to cover type-directed macro expansion resulting in a single, uniform system offering multiple abstraction levels that range from supporting simplest syntax sugars to elaboration of formerly baked-in syntax. We have implemented our new macro system and integrated it into the new version of the Lean theorem prover, Lean 4. Despite its expressivity, the macro system is simple enough that it can easily be integrated into other systems.},
  langid = {english},
  keywords = {Computer Science - Programming Languages},
  file = {/home/alex/Zotero/storage/VQABD6ES/Ullrich_de Moura_2022_Beyond Notations.pdf}
}

@article{xiaInteractionTreesRepresenting2020,
  title = {Interaction Trees: Representing Recursive and Impure Programs in {{Coq}}},
  shorttitle = {Interaction Trees},
  author = {Xia, Li-yao and Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Malecha, Gregory and Pierce, Benjamin C. and Zdancewic, Steve},
  date = {2020-01},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {4},
  pages = {1--32},
  issn = {2475-1421},
  doi = {10.1145/3371119},
  url = {https://dl.acm.org/doi/10.1145/3371119},
  urldate = {2024-02-18},
  abstract = {Interaction trees               (ITrees) are a general-purpose data structure for representing the behaviors of recursive programs that interact with their environments. A coinductive variant of “free monads,” ITrees are built out of uninterpreted events and their continuations. They support compositional construction of interpreters from               event handlers               , which give meaning to events by defining their semantics as monadic actions. ITrees are expressive enough to represent impure and potentially nonterminating, mutually recursive computations, while admitting a rich equational theory of equivalence up to weak bisimulation. In contrast to other approaches such as relationally specified operational semantics, ITrees are executable via code extraction, making them suitable for debugging, testing, and implementing software artifacts that are amenable to formal verification.                          We have implemented ITrees and their associated theory as a Coq library, mechanizing classic domain- and category-theoretic results about program semantics, iteration, monadic structures, and equational reasoning. Although the internals of the library rely heavily on coinductive proofs, the interface hides these details so that clients can use and reason about ITrees without explicit use of Coq’s coinduction tactics.             To showcase the utility of our theory, we prove the termination-sensitive correctness of a compiler from a simple imperative source language to an assembly-like target whose meanings are given in an ITree-based denotational semantics. Unlike previous results using operational techniques, our bisimulation proof follows straightforwardly by structural induction and elementary rewriting via an equational theory of combinators for control-flow graphs.},
  issue = {POPL},
  langid = {english},
  file = {/home/alex/Zotero/storage/NEBX3SPG/Xia et al. - 2020 - Interaction trees representing recursive and impu.pdf}
}

@inproceedings{yangFindingUnderstandingBugs2011,
  title = {Finding and Understanding Bugs in {{C}} Compilers},
  booktitle = {Proceedings of the 32nd {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
  date = {2011-06-04},
  series = {{{PLDI}} '11},
  pages = {283--294},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1993498.1993532},
  url = {https://doi.org/10.1145/1993498.1993532},
  urldate = {2024-06-05},
  abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to find compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our first contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undefined and unspecified behaviors that would destroy its ability to automatically find wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
  isbn = {978-1-4503-0663-8},
  keywords = {automated testing,compiler defect,compiler testing,random program generation,random testing},
  file = {/home/alex/Zotero/storage/HWWTGYM3/Yang et al_2011_Finding and understanding bugs in C compilers.pdf}
}
